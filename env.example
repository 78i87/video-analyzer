# Required
OPENROUTER_API_KEY=

# Optional overrides
# Note: This project sends image frames via `image_url`, so your model must support image input.
# Example vision models: openai/gpt-4o-mini, google/gemini-1.5-flash
OPENROUTER_MODEL=nvidia/nemotron-nano-12b-v2-vl:free
# Optional comma-separated list of fallback models to try if the primary model returns
# recoverable errors (429 or 5xx). Defaults include google/gemma and amazon/nova.
OPENROUTER_MODEL_FALLBACK=google/gemma-3-27b-it:free,amazon/nova-2-lite-v1:free
# Maximum attempts (primary + fallbacks). Defaults to number of models available.
OPENROUTER_MODEL_MAX_ATTEMPTS=3
LOG_LEVEL=info
LOG_MODEL_OUTPUT=0
# Also writes per-segment model output to a JSONL file under AGENT_OUTPUT_LOG_DIR.
AGENT_OUTPUT_LOG=0
AGENT_OUTPUT_LOG_DIR=data/agent-logs
PROGRESS_UI=1
FFMPEG_BIN=ffmpeg
FFMPEG_PROBE_BIN=ffprobe
WHISPER_BIN=
WHISPER_ARGS=
FRAME_DIR=data/frames
AUDIO_DIR=data/audio
SEGMENT_INTERVAL_SECONDS=1
AGENT_COUNT=5
